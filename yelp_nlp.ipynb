{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/saehuh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saehuh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/saehuh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/saehuh/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "reviews=[]\n",
    "with open('data/yelp_dataset/yelp_academic_dataset_review.json') as f:\n",
    "    for line in f:\n",
    "        reviews.append(json.loads(line))\n",
    "reviews_df=pd.DataFrame.from_dict(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xQY8N_XvtGbearJ5X4QryQ</td>\n",
       "      <td>OwjRMXRC0KyPrIlcjaXeFQ</td>\n",
       "      <td>-MhfebM0QIsKt87iDN-FNw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>As someone who has worked with many museums, I...</td>\n",
       "      <td>2015-04-15 05:21:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UmFMZ8PyXZTY2QcwzsfQYA</td>\n",
       "      <td>nIJD_7ZXHq-FX8byPMOkMQ</td>\n",
       "      <td>lbrU8StCq3yDfr-QMnGrmQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am actually horrified this place is still in...</td>\n",
       "      <td>2013-12-07 03:16:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG2ZaYiOgpr2DK_90pYjNw</td>\n",
       "      <td>V34qejxNsCbcgD8C0HVk-Q</td>\n",
       "      <td>HQl28KMwrEKHqhFrrDqVNQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love Deagan's. I do. I really do. The atmosp...</td>\n",
       "      <td>2015-12-05 03:18:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i6g_oA9Yf9Y31qt0wibXpw</td>\n",
       "      <td>ofKDkJKXSKZXu5xJNGiiBQ</td>\n",
       "      <td>5JxlZaqCnk1MnbgRirs40Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dismal, lukewarm, defrosted-tasting \"TexMex\" g...</td>\n",
       "      <td>2011-05-27 05:30:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6TdNDKywdbjoTkizeMce8A</td>\n",
       "      <td>UgMW8bLE0QMJDCkQ1Ax5Mg</td>\n",
       "      <td>IS4cv902ykd8wj1TR0N3-A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh happy day, finally have a Canes near my cas...</td>\n",
       "      <td>2017-01-14 21:56:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  xQY8N_XvtGbearJ5X4QryQ  OwjRMXRC0KyPrIlcjaXeFQ  -MhfebM0QIsKt87iDN-FNw   \n",
       "1  UmFMZ8PyXZTY2QcwzsfQYA  nIJD_7ZXHq-FX8byPMOkMQ  lbrU8StCq3yDfr-QMnGrmQ   \n",
       "2  LG2ZaYiOgpr2DK_90pYjNw  V34qejxNsCbcgD8C0HVk-Q  HQl28KMwrEKHqhFrrDqVNQ   \n",
       "3  i6g_oA9Yf9Y31qt0wibXpw  ofKDkJKXSKZXu5xJNGiiBQ  5JxlZaqCnk1MnbgRirs40Q   \n",
       "4  6TdNDKywdbjoTkizeMce8A  UgMW8bLE0QMJDCkQ1Ax5Mg  IS4cv902ykd8wj1TR0N3-A   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    2.0       5      0     0   \n",
       "1    1.0       1      1     0   \n",
       "2    5.0       1      0     0   \n",
       "3    1.0       0      0     0   \n",
       "4    4.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  As someone who has worked with many museums, I...  2015-04-15 05:21:16  \n",
       "1  I am actually horrified this place is still in...  2013-12-07 03:16:52  \n",
       "2  I love Deagan's. I do. I really do. The atmosp...  2015-12-05 03:18:11  \n",
       "3  Dismal, lukewarm, defrosted-tasting \"TexMex\" g...  2011-05-27 05:30:52  \n",
       "4  Oh happy day, finally have a Canes near my cas...  2017-01-14 21:56:57  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8021122, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_csv(\"data/yelp_business.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209393, 16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5fb9532f5884f05b67a0dca5</td>\n",
       "      <td>f9NumwFMBDn751xgFiRbNA</td>\n",
       "      <td>The Range At Lake Norman</td>\n",
       "      <td>10913 Bailey Rd</td>\n",
       "      <td>Cornelius</td>\n",
       "      <td>NC</td>\n",
       "      <td>28031</td>\n",
       "      <td>35.462724</td>\n",
       "      <td>-80.852612</td>\n",
       "      <td>3.5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'BikePa...</td>\n",
       "      <td>Active Life, Gun/Rifle Ranges, Guns &amp; Ammo, Sh...</td>\n",
       "      <td>{'Monday': '10:0-18:0', 'Tuesday': '11:0-20:0'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5fb9532f5884f05b67a0dca6</td>\n",
       "      <td>51M2Kk903DFYI6gnB5I6SQ</td>\n",
       "      <td>USE MY GUY SERVICES LLC</td>\n",
       "      <td>4827 E Downing Cir</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85205</td>\n",
       "      <td>33.428065</td>\n",
       "      <td>-111.726649</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'ByAppo...</td>\n",
       "      <td>Home Services, Plumbing, Electricians, Handyma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '9:0-16:0', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5fb9532f5884f05b67a0dca7</td>\n",
       "      <td>cKyLV5oWZJ2NudWgqs8VZw</td>\n",
       "      <td>Oasis Auto Center - Gilbert</td>\n",
       "      <td>1720 W Elliot Rd, Ste 105</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85233</td>\n",
       "      <td>33.350399</td>\n",
       "      <td>-111.827142</td>\n",
       "      <td>4.5</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Auto Repair, Automotive, Oil Change Stations, ...</td>\n",
       "      <td>{'Monday': '7:0-18:0', 'Tuesday': '7:0-18:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5fb9532f5884f05b67a0dca8</td>\n",
       "      <td>oiAlXZPIFm2nBCt0DHLu_Q</td>\n",
       "      <td>Green World Cleaners</td>\n",
       "      <td>6870 S Rainbow Blvd, Ste 117</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89118</td>\n",
       "      <td>36.063977</td>\n",
       "      <td>-115.241463</td>\n",
       "      <td>3.5</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': \"{'garage': False, 'street...</td>\n",
       "      <td>Dry Cleaning &amp; Laundry, Local Services, Laundr...</td>\n",
       "      <td>{'Monday': '7:0-19:0', 'Tuesday': '7:0-19:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5fb9532f5884f05b67a0dca9</td>\n",
       "      <td>XNoUzKckATkOD1hP6vghZg</td>\n",
       "      <td>Felinus</td>\n",
       "      <td>3554 Rue Notre-Dame O</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>QC</td>\n",
       "      <td>H4C 1P4</td>\n",
       "      <td>45.479984</td>\n",
       "      <td>-73.580070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pets, Pet Services, Pet Groomers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       _id             business_id  \\\n",
       "0           0  5fb9532f5884f05b67a0dca5  f9NumwFMBDn751xgFiRbNA   \n",
       "1           1  5fb9532f5884f05b67a0dca6  51M2Kk903DFYI6gnB5I6SQ   \n",
       "2           2  5fb9532f5884f05b67a0dca7  cKyLV5oWZJ2NudWgqs8VZw   \n",
       "3           3  5fb9532f5884f05b67a0dca8  oiAlXZPIFm2nBCt0DHLu_Q   \n",
       "4           4  5fb9532f5884f05b67a0dca9  XNoUzKckATkOD1hP6vghZg   \n",
       "\n",
       "                          name                       address       city state  \\\n",
       "0     The Range At Lake Norman               10913 Bailey Rd  Cornelius    NC   \n",
       "1      USE MY GUY SERVICES LLC            4827 E Downing Cir       Mesa    AZ   \n",
       "2  Oasis Auto Center - Gilbert     1720 W Elliot Rd, Ste 105    Gilbert    AZ   \n",
       "3         Green World Cleaners  6870 S Rainbow Blvd, Ste 117  Las Vegas    NV   \n",
       "4                      Felinus         3554 Rue Notre-Dame O   Montreal    QC   \n",
       "\n",
       "  postal_code   latitude   longitude  stars  review_count  is_open  \\\n",
       "0       28031  35.462724  -80.852612    3.5            36        1   \n",
       "1       85205  33.428065 -111.726649    4.5            26        1   \n",
       "2       85233  33.350399 -111.827142    4.5            38        1   \n",
       "3       89118  36.063977 -115.241463    3.5            81        1   \n",
       "4     H4C 1P4  45.479984  -73.580070    5.0             5        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'BusinessAcceptsCreditCards': 'True', 'BikePa...   \n",
       "1  {'BusinessAcceptsCreditCards': 'True', 'ByAppo...   \n",
       "2             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "3  {'BusinessParking': \"{'garage': False, 'street...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Active Life, Gun/Rifle Ranges, Guns & Ammo, Sh...   \n",
       "1  Home Services, Plumbing, Electricians, Handyma...   \n",
       "2  Auto Repair, Automotive, Oil Change Stations, ...   \n",
       "3  Dry Cleaning & Laundry, Local Services, Laundr...   \n",
       "4                   Pets, Pet Services, Pet Groomers   \n",
       "\n",
       "                                               hours  \n",
       "0  {'Monday': '10:0-18:0', 'Tuesday': '11:0-20:0'...  \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '9:0-16:0', '...  \n",
       "2  {'Monday': '7:0-18:0', 'Tuesday': '7:0-18:0', ...  \n",
       "3  {'Monday': '7:0-19:0', 'Tuesday': '7:0-19:0', ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', '_id', 'business_id', 'name', 'address', 'city', 'state',\n",
      "       'postal_code', 'latitude', 'longitude', 'stars', 'review_count',\n",
      "       'is_open', 'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n",
      "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
      "       'cool', 'text', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#dataframe columns\n",
    "print(business_df.columns)\n",
    "print(reviews_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id       object\n",
       "user_id         object\n",
       "business_id     object\n",
       "stars          float64\n",
       "useful           int64\n",
       "funny            int64\n",
       "cool             int64\n",
       "text            object\n",
       "date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to know datatypes of each column in reviews\n",
    "reviews_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "_id                 0\n",
       "business_id         0\n",
       "name                1\n",
       "address          8679\n",
       "city                2\n",
       "state               0\n",
       "postal_code       509\n",
       "latitude            0\n",
       "longitude           0\n",
       "stars               0\n",
       "review_count        0\n",
       "is_open             0\n",
       "attributes      29045\n",
       "categories        524\n",
       "hours           44843\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking each column to know how many null values business dataframe has\n",
    "business_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "user_id        0\n",
       "business_id    0\n",
       "stars          0\n",
       "useful         0\n",
       "funny          0\n",
       "cool           0\n",
       "text           0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking each column to know how many null values reviews dataframe has\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to group all the reviews by each business\n",
    "review_df_agg=reviews_df.groupby('business_id')['text'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns business_id for index and all_reviews for all aggregated reviews\n",
    "review_df_for_sklearn=pd.DataFrame({'business_id':review_df_agg.index,'all_reviews':review_df_agg.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging both reviews and business dataframes on column business_id as it the unique and common column for both dataframes\n",
    "review_business=pd.merge(review_df_for_sklearn,business_df,on='business_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209393, 17)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape of merged dataframe\n",
    "review_business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20939, 17)\n"
     ]
    }
   ],
   "source": [
    "#taking the sample of  10% from the whole dataframe \n",
    "review_business_sample=review_business.sample(frac=.10)\n",
    "print(review_business_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>all_reviews</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191028</th>\n",
       "      <td>uP7ojXytz8q7YZbQLNibow</td>\n",
       "      <td>J'ai été un jeudi 5à7. De plus, soir de match....</td>\n",
       "      <td>194625</td>\n",
       "      <td>5fb9533c5884f05b67a3d4e6</td>\n",
       "      <td>Lobby Bar</td>\n",
       "      <td>4538 Avenue Papineau</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>QC</td>\n",
       "      <td>H2H 1V3</td>\n",
       "      <td>45.533121</td>\n",
       "      <td>-73.575493</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'HasTV': 'True', 'RestaurantsPriceRange2': '2...</td>\n",
       "      <td>Canadian (New), Nightlife, Indian, Restaurants...</td>\n",
       "      <td>{'Tuesday': '17:0-3:0', 'Wednesday': '17:0-3:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79538</th>\n",
       "      <td>NJdJ5F1SAHBtQg9QvOsQ8g</td>\n",
       "      <td>Shane at We Do It Pools in Tempe has been my p...</td>\n",
       "      <td>52789</td>\n",
       "      <td>5fb953335884f05b67a1aada</td>\n",
       "      <td>We Do It Pools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85280</td>\n",
       "      <td>33.430000</td>\n",
       "      <td>-111.930000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Busine...</td>\n",
       "      <td>Pool Cleaners, Home Services, Pool &amp; Hot Tub S...</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170022</th>\n",
       "      <td>nvhKzcD6DKssgMuadrSFoA</td>\n",
       "      <td>Sunday 12/17/2017 6pm\\n\\nFirst and foremost, t...</td>\n",
       "      <td>66802</td>\n",
       "      <td>5fb953345884f05b67a1e197</td>\n",
       "      <td>Harris Teeter</td>\n",
       "      <td>9925 Rose Commons Dr</td>\n",
       "      <td>Huntersville</td>\n",
       "      <td>NC</td>\n",
       "      <td>28078</td>\n",
       "      <td>35.409242</td>\n",
       "      <td>-80.862122</td>\n",
       "      <td>3.5</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsPriceRange2': '2', 'BusinessParki...</td>\n",
       "      <td>Shopping, Food, Drugstores, Grocery</td>\n",
       "      <td>{'Monday': '6:0-0:0', 'Tuesday': '6:0-0:0', 'W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164805</th>\n",
       "      <td>mLjDh0vQYBCY6g9T1HczVw</td>\n",
       "      <td>Bar staff did not know pricing on the draft be...</td>\n",
       "      <td>144300</td>\n",
       "      <td>5fb953395884f05b67a31051</td>\n",
       "      <td>Great Lakes Brewing</td>\n",
       "      <td>5300 Riverside Dr</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44135</td>\n",
       "      <td>41.408042</td>\n",
       "      <td>-81.841198</td>\n",
       "      <td>3.5</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForKids': 'False', 'BikeParking': 'False...</td>\n",
       "      <td>Brewpubs, Nightlife, Pubs, Breweries, Food, Ba...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199048</th>\n",
       "      <td>wq2_ZM7KU_Wc93tonTTsdQ</td>\n",
       "      <td>My boyfriend and I found Rockne's actually whi...</td>\n",
       "      <td>48607</td>\n",
       "      <td>5fb953325884f05b67a19a84</td>\n",
       "      <td>Rockne's</td>\n",
       "      <td>4240 Hudson Dr</td>\n",
       "      <td>Stow</td>\n",
       "      <td>OH</td>\n",
       "      <td>44224</td>\n",
       "      <td>41.182742</td>\n",
       "      <td>-81.472614</td>\n",
       "      <td>3.5</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForKids': 'True', 'BusinessParking': \"{'...</td>\n",
       "      <td>Restaurants, American (Traditional)</td>\n",
       "      <td>{'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  \\\n",
       "191028  uP7ojXytz8q7YZbQLNibow   \n",
       "79538   NJdJ5F1SAHBtQg9QvOsQ8g   \n",
       "170022  nvhKzcD6DKssgMuadrSFoA   \n",
       "164805  mLjDh0vQYBCY6g9T1HczVw   \n",
       "199048  wq2_ZM7KU_Wc93tonTTsdQ   \n",
       "\n",
       "                                              all_reviews  Unnamed: 0  \\\n",
       "191028  J'ai été un jeudi 5à7. De plus, soir de match....      194625   \n",
       "79538   Shane at We Do It Pools in Tempe has been my p...       52789   \n",
       "170022  Sunday 12/17/2017 6pm\\n\\nFirst and foremost, t...       66802   \n",
       "164805  Bar staff did not know pricing on the draft be...      144300   \n",
       "199048  My boyfriend and I found Rockne's actually whi...       48607   \n",
       "\n",
       "                             _id                 name               address  \\\n",
       "191028  5fb9533c5884f05b67a3d4e6            Lobby Bar  4538 Avenue Papineau   \n",
       "79538   5fb953335884f05b67a1aada       We Do It Pools                   NaN   \n",
       "170022  5fb953345884f05b67a1e197        Harris Teeter  9925 Rose Commons Dr   \n",
       "164805  5fb953395884f05b67a31051  Great Lakes Brewing     5300 Riverside Dr   \n",
       "199048  5fb953325884f05b67a19a84             Rockne's        4240 Hudson Dr   \n",
       "\n",
       "                city state postal_code   latitude   longitude  stars  \\\n",
       "191028      Montréal    QC     H2H 1V3  45.533121  -73.575493    2.5   \n",
       "79538          Tempe    AZ       85280  33.430000 -111.930000    4.0   \n",
       "170022  Huntersville    NC       28078  35.409242  -80.862122    3.5   \n",
       "164805     Cleveland    OH       44135  41.408042  -81.841198    3.5   \n",
       "199048          Stow    OH       44224  41.182742  -81.472614    3.5   \n",
       "\n",
       "        review_count  is_open  \\\n",
       "191028             8        1   \n",
       "79538              3        1   \n",
       "170022            33        1   \n",
       "164805           173        1   \n",
       "199048            43        1   \n",
       "\n",
       "                                               attributes  \\\n",
       "191028  {'HasTV': 'True', 'RestaurantsPriceRange2': '2...   \n",
       "79538   {'BusinessAcceptsCreditCards': 'True', 'Busine...   \n",
       "170022  {'RestaurantsPriceRange2': '2', 'BusinessParki...   \n",
       "164805  {'GoodForKids': 'False', 'BikeParking': 'False...   \n",
       "199048  {'GoodForKids': 'True', 'BusinessParking': \"{'...   \n",
       "\n",
       "                                               categories  \\\n",
       "191028  Canadian (New), Nightlife, Indian, Restaurants...   \n",
       "79538   Pool Cleaners, Home Services, Pool & Hot Tub S...   \n",
       "170022                Shopping, Food, Drugstores, Grocery   \n",
       "164805  Brewpubs, Nightlife, Pubs, Breweries, Food, Ba...   \n",
       "199048                Restaurants, American (Traditional)   \n",
       "\n",
       "                                                    hours  \n",
       "191028  {'Tuesday': '17:0-3:0', 'Wednesday': '17:0-3:0...  \n",
       "79538   {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...  \n",
       "170022  {'Monday': '6:0-0:0', 'Tuesday': '6:0-0:0', 'W...  \n",
       "164805                                                NaN  \n",
       "199048  {'Monday': '11:0-21:0', 'Tuesday': '11:0-21:0'...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overview of merged dataframe\n",
    "review_business_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20939,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as the review_count has different values it needs to be normalized\n",
    "from scipy.stats import zscore\n",
    "\n",
    "review_count_normalized=zscore(review_business_sample['review_count'])\n",
    "review_count_normalized.shape #normalized review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF(Term Frequency- Inverse Document Frequency): It is a numerical statistic that is intended to reflect how important a word is in document in a collection. The tf-idf value increases proportionality to the number of times a word appears in the document and is offset by the number of documnets in the corpus that contain the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03040371 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.05623942 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01301894 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02281133 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#using tf-idf to do feature extraction from review contents for models\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "vectorizer=sk_text.TfidfVectorizer(stop_words='english',max_features=1000,min_df=2)\n",
    "matrix=vectorizer.fit_transform(review_business_sample['all_reviews'])\n",
    "\n",
    "print(type(matrix))\n",
    "print(matrix.toarray())\n",
    "\n",
    "#print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the matrix to array format\n",
    "tfif_data=matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20939, 1000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#know the shape of the previous array\n",
    "tfif_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.20191498],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.23575344],\n",
       "       [ 0.        ,  0.03040371,  0.        , ...,  0.        ,\n",
       "         0.        , -0.03272273],\n",
       "       ...,\n",
       "       [ 0.        ,  0.05623942,  0.        , ...,  0.        ,\n",
       "         0.        , -0.22898575],\n",
       "       [ 0.        ,  0.01301894,  0.        , ...,  0.        ,\n",
       "         0.        , -0.16130884],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.0530258 ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging review_count and tfid_data arrays\n",
    "import numpy as np\n",
    "concat_matrix=np.column_stack((tfif_data,review_count_normalized))\n",
    "concat_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Linear Regression - Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16751, 1001)\n",
      "(4188, 1001)\n"
     ]
    }
   ],
   "source": [
    "#applying linear regression model by giving X as concat matrix and y as stars column\n",
    "\n",
    "# import the class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X=concat_matrix\n",
    "y=review_business_sample['stars']\n",
    "\n",
    "#dividing the data in to training and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state =1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.2851802759613898\n",
      "Final score (RMSE): 0.5340227298171771\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "lr=LinearRegression()\n",
    "\n",
    "# fit the model with data\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifcation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os , io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#one hot encoding on stars column \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(review_business_sample['stars'])\n",
    "\n",
    "list(le.classes_)\n",
    "\n",
    "y = le.transform(review_business_sample['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in to training and test datasets\n",
    "X_train, X_test,y_train,y_test = train_test_split(concat_matrix,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on test set: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print('Accuracy of SVM on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn classfrom sklearn.neighbors import KNeighborsClassifierifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of nearest neighbor classifier on test set: 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy of nearest neighbor classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saehuh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic Regression\n",
    "\n",
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Normalization for Multionominal Naive Bayes as it does not take negative values which happens in z-score normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax=review_business_sample['review_count'].max()-review_business_sample['review_count'].min()\n",
    "nmn_reviewcount=(review_business_sample['review_count']-review_business_sample['review_count'].min())/minmax\n",
    "nmn_rc_nparray=nmn_reviewcount.values\n",
    "nmn_rc_nparray.shape\n",
    "import numpy as np\n",
    "concat_matrix=np.column_stack((tfif_data,nmn_rc_nparray))\n",
    "X=concat_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Nominal Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial on test set: 0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Accuracy of Multinomial on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Business Rating Prediction using Tensor Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensor Flow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "x=concat_matrix\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(review_business_sample['stars'])\n",
    "\n",
    "list(le.classes_)\n",
    "\n",
    "y = le.transform(review_business_sample['stars'])\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "655/655 - 1s - loss: 5.5751\n",
      "Epoch 2/100\n",
      "655/655 - 1s - loss: 1.1957\n",
      "Epoch 3/100\n",
      "655/655 - 1s - loss: 1.0471\n",
      "Epoch 4/100\n",
      "655/655 - 1s - loss: 0.9177\n",
      "Epoch 5/100\n",
      "655/655 - 1s - loss: 0.8265\n",
      "Epoch 6/100\n",
      "655/655 - 1s - loss: 0.7561\n",
      "Epoch 7/100\n",
      "655/655 - 1s - loss: 0.6931\n",
      "Epoch 8/100\n",
      "655/655 - 1s - loss: 0.6292\n",
      "Epoch 9/100\n",
      "655/655 - 1s - loss: 0.5702\n",
      "Epoch 10/100\n",
      "655/655 - 1s - loss: 0.5228\n",
      "Epoch 11/100\n",
      "655/655 - 1s - loss: 0.4840\n",
      "Epoch 12/100\n",
      "655/655 - 1s - loss: 0.4489\n",
      "Epoch 13/100\n",
      "655/655 - 1s - loss: 0.4219\n",
      "Epoch 14/100\n",
      "655/655 - 1s - loss: 0.3999\n",
      "Epoch 15/100\n",
      "655/655 - 1s - loss: 0.3770\n",
      "Epoch 16/100\n",
      "655/655 - 1s - loss: 0.3573\n",
      "Epoch 17/100\n",
      "655/655 - 1s - loss: 0.3401\n",
      "Epoch 18/100\n",
      "655/655 - 1s - loss: 0.3269\n",
      "Epoch 19/100\n",
      "655/655 - 1s - loss: 0.3103\n",
      "Epoch 20/100\n",
      "655/655 - 1s - loss: 0.2960\n",
      "Epoch 21/100\n",
      "655/655 - 1s - loss: 0.2855\n",
      "Epoch 22/100\n",
      "655/655 - 1s - loss: 0.2730\n",
      "Epoch 23/100\n",
      "655/655 - 1s - loss: 0.2639\n",
      "Epoch 24/100\n",
      "655/655 - 1s - loss: 0.2555\n",
      "Epoch 25/100\n",
      "655/655 - 1s - loss: 0.2486\n",
      "Epoch 26/100\n",
      "655/655 - 1s - loss: 0.2415\n",
      "Epoch 27/100\n",
      "655/655 - 1s - loss: 0.2363\n",
      "Epoch 28/100\n",
      "655/655 - 1s - loss: 0.2277\n",
      "Epoch 29/100\n",
      "655/655 - 1s - loss: 0.2218\n",
      "Epoch 30/100\n",
      "655/655 - 1s - loss: 0.2173\n",
      "Epoch 31/100\n",
      "655/655 - 1s - loss: 0.2126\n",
      "Epoch 32/100\n",
      "655/655 - 1s - loss: 0.2069\n",
      "Epoch 33/100\n",
      "655/655 - 1s - loss: 0.2048\n",
      "Epoch 34/100\n",
      "655/655 - 1s - loss: 0.1989\n",
      "Epoch 35/100\n",
      "655/655 - 1s - loss: 0.1973\n",
      "Epoch 36/100\n",
      "655/655 - 1s - loss: 0.1889\n",
      "Epoch 37/100\n",
      "655/655 - 1s - loss: 0.1888\n",
      "Epoch 38/100\n",
      "655/655 - 1s - loss: 0.1862\n",
      "Epoch 39/100\n",
      "655/655 - 1s - loss: 0.1803\n",
      "Epoch 40/100\n",
      "655/655 - 1s - loss: 0.1767\n",
      "Epoch 41/100\n",
      "655/655 - 1s - loss: 0.1739\n",
      "Epoch 42/100\n",
      "655/655 - 1s - loss: 0.1723\n",
      "Epoch 43/100\n",
      "655/655 - 1s - loss: 0.1687\n",
      "Epoch 44/100\n",
      "655/655 - 1s - loss: 0.1671\n",
      "Epoch 45/100\n",
      "655/655 - 1s - loss: 0.1638\n",
      "Epoch 46/100\n",
      "655/655 - 1s - loss: 0.1605\n",
      "Epoch 47/100\n",
      "655/655 - 1s - loss: 0.1584\n",
      "Epoch 48/100\n",
      "655/655 - 1s - loss: 0.1558\n",
      "Epoch 49/100\n",
      "655/655 - 1s - loss: 0.1529\n",
      "Epoch 50/100\n",
      "655/655 - 1s - loss: 0.1516\n",
      "Epoch 51/100\n",
      "655/655 - 1s - loss: 0.1511\n",
      "Epoch 52/100\n",
      "655/655 - 1s - loss: 0.1465\n",
      "Epoch 53/100\n",
      "655/655 - 1s - loss: 0.1445\n",
      "Epoch 54/100\n",
      "655/655 - 1s - loss: 0.1434\n",
      "Epoch 55/100\n",
      "655/655 - 1s - loss: 0.1399\n",
      "Epoch 56/100\n",
      "655/655 - 1s - loss: 0.1394\n",
      "Epoch 57/100\n",
      "655/655 - 1s - loss: 0.1363\n",
      "Epoch 58/100\n",
      "655/655 - 1s - loss: 0.1360\n",
      "Epoch 59/100\n",
      "655/655 - 1s - loss: 0.1319\n",
      "Epoch 60/100\n",
      "655/655 - 1s - loss: 0.1294\n",
      "Epoch 61/100\n",
      "655/655 - 1s - loss: 0.1275\n",
      "Epoch 62/100\n",
      "655/655 - 1s - loss: 0.1285\n",
      "Epoch 63/100\n",
      "655/655 - 1s - loss: 0.1252\n",
      "Epoch 64/100\n",
      "655/655 - 1s - loss: 0.1229\n",
      "Epoch 65/100\n",
      "655/655 - 1s - loss: 0.1211\n",
      "Epoch 66/100\n",
      "655/655 - 1s - loss: 0.1197\n",
      "Epoch 67/100\n",
      "655/655 - 1s - loss: 0.1188\n",
      "Epoch 68/100\n",
      "655/655 - 1s - loss: 0.1161\n",
      "Epoch 69/100\n",
      "655/655 - 1s - loss: 0.1154\n",
      "Epoch 70/100\n",
      "655/655 - 1s - loss: 0.1149\n",
      "Epoch 71/100\n",
      "655/655 - 1s - loss: 0.1131\n",
      "Epoch 72/100\n",
      "655/655 - 1s - loss: 0.1092\n",
      "Epoch 73/100\n",
      "655/655 - 1s - loss: 0.1103\n",
      "Epoch 74/100\n",
      "655/655 - 1s - loss: 0.1081\n",
      "Epoch 75/100\n",
      "655/655 - 1s - loss: 0.1055\n",
      "Epoch 76/100\n",
      "655/655 - 1s - loss: 0.1048\n",
      "Epoch 77/100\n",
      "655/655 - 1s - loss: 0.1032\n",
      "Epoch 78/100\n",
      "655/655 - 1s - loss: 0.1029\n",
      "Epoch 79/100\n",
      "655/655 - 1s - loss: 0.1012\n",
      "Epoch 80/100\n",
      "655/655 - 1s - loss: 0.0989\n",
      "Epoch 81/100\n",
      "655/655 - 1s - loss: 0.0981\n",
      "Epoch 82/100\n",
      "655/655 - 1s - loss: 0.0977\n",
      "Epoch 83/100\n",
      "655/655 - 1s - loss: 0.0966\n",
      "Epoch 84/100\n",
      "655/655 - 1s - loss: 0.0950\n",
      "Epoch 85/100\n",
      "655/655 - 1s - loss: 0.0944\n",
      "Epoch 86/100\n",
      "655/655 - 1s - loss: 0.0956\n",
      "Epoch 87/100\n",
      "655/655 - 1s - loss: 0.0915\n",
      "Epoch 88/100\n",
      "655/655 - 1s - loss: 0.0923\n",
      "Epoch 89/100\n",
      "655/655 - 1s - loss: 0.0904\n",
      "Epoch 90/100\n",
      "655/655 - 1s - loss: 0.0897\n",
      "Epoch 91/100\n",
      "655/655 - 1s - loss: 0.0880\n",
      "Epoch 92/100\n",
      "655/655 - 1s - loss: 0.0882\n",
      "Epoch 93/100\n",
      "655/655 - 1s - loss: 0.0876\n",
      "Epoch 94/100\n",
      "655/655 - 1s - loss: 0.0862\n",
      "Epoch 95/100\n",
      "655/655 - 1s - loss: 0.0843\n",
      "Epoch 96/100\n",
      "655/655 - 1s - loss: 0.0844\n",
      "Epoch 97/100\n",
      "655/655 - 1s - loss: 0.0842\n",
      "Epoch 98/100\n",
      "655/655 - 1s - loss: 0.0812\n",
      "Epoch 99/100\n",
      "655/655 - 1s - loss: 0.0816\n",
      "Epoch 100/100\n",
      "655/655 - 1s - loss: 0.0822\n",
      "Shape: (20939, 1)\n",
      "[[2.9826798]\n",
      " [5.8689322]\n",
      " [4.9114623]\n",
      " ...\n",
      " [3.948811 ]\n",
      " [3.637256 ]\n",
      " [5.027641 ]]\n",
      "Final score (RMSE): 0.27097113633975245\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(1)) # Output\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(x,y,verbose=2,epochs=100)    # Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "pred = model.predict(x)\n",
    "print(\"Shape: {}\".format(pred.shape))\n",
    "print(pred)\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "491/491 - 2s - loss: 2.0597 - val_loss: 1.0861\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.0311 - val_loss: 1.0095\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 0.8781 - val_loss: 0.9312\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 0.7596 - val_loss: 0.9362\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 0.6561 - val_loss: 0.9759\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 0.5541 - val_loss: 1.1212\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 0.4609 - val_loss: 1.0418\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 0.3810 - val_loss: 1.0475\n",
      "Epoch 00008: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "491/491 - 2s - loss: 2.2138 - val_loss: 1.2273\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.0501 - val_loss: 1.0000\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 0.8920 - val_loss: 0.9503\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 0.7881 - val_loss: 0.9788\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 0.6901 - val_loss: 0.9435\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 0.5946 - val_loss: 1.0847\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 0.5026 - val_loss: 1.0718\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 0.4218 - val_loss: 1.0234\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 0.3591 - val_loss: 1.0853\n",
      "Epoch 10/100\n",
      "491/491 - 1s - loss: 0.3056 - val_loss: 1.0853\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "491/491 - 1s - loss: 2.0938 - val_loss: 1.0964\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.0286 - val_loss: 1.0508\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 0.8801 - val_loss: 1.0483\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 0.7626 - val_loss: 0.9296\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 0.6566 - val_loss: 1.0470\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 0.5470 - val_loss: 0.9914\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 0.4612 - val_loss: 1.2059\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 0.3828 - val_loss: 1.0330\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 0.3246 - val_loss: 1.1506\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "491/491 - 3s - loss: 2.2064 - val_loss: 1.3055\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.0492 - val_loss: 1.0255\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 0.8973 - val_loss: 0.9868\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 0.7812 - val_loss: 0.9771\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 0.6802 - val_loss: 0.9806\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 0.5761 - val_loss: 0.9780\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 0.4902 - val_loss: 1.0587\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 0.4076 - val_loss: 1.0547\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 0.3450 - val_loss: 1.0713\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "491/491 - 1s - loss: 2.2901 - val_loss: 1.1254\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.0578 - val_loss: 1.1203\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 0.9042 - val_loss: 0.9574\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 0.7856 - val_loss: 0.9172\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 0.6766 - val_loss: 0.9982\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 0.5807 - val_loss: 0.9839\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 0.4925 - val_loss: 1.0065\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 0.4201 - val_loss: 1.0297\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 0.3543 - val_loss: 1.0550\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "Final score (MSE): 0.9171952647514374\n",
      "Final score (RMSE): 0.9577031193180052\n"
     ]
    }
   ],
   "source": [
    "# Define ModelCheckpoint outside the loop\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weight1.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    # Build network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1)) # Output\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n",
    "\n",
    "\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights(\"best_weight1.hdf5\") # load weights from best model\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Measure MSE error.  \n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Flow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io , os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(review_business_sample['stars'])\n",
    "\n",
    "list(le1.classes_)\n",
    "y1=le1.transform(review_business_sample['stars'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'all_reviews', 'Unnamed: 0', '_id', 'name', 'address',\n",
      "       'city', 'state', 'postal_code', 'latitude', 'longitude', 'review_count',\n",
      "       'is_open', 'attributes', 'categories', 'hours', 'stars-1.0',\n",
      "       'stars-1.5', 'stars-2.0', 'stars-2.5', 'stars-3.0', 'stars-3.5',\n",
      "       'stars-4.0', 'stars-4.5', 'stars-5.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y1= encode_text_dummy(review_business_sample,\"stars\")   #one-hot coding\n",
    "y1= review_business_sample\n",
    "print(y1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=y1[['stars-1.0', 'stars-1.5','stars-2.0', 'stars-2.5', 'stars-3.0', 'stars-3.5', 'stars-4.0','stars-4.5', 'stars-5.0']]\n",
    "y1=y1.values\n",
    "type(y1)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n",
      "491/491 - 1s - loss: 1.7299 - val_loss: 1.3779\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.2925 - val_loss: 1.2651\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 1.2154 - val_loss: 1.2469\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 1.1807 - val_loss: 1.2316\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 1.1531 - val_loss: 1.2494\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 1.1291 - val_loss: 1.2319\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 1.1072 - val_loss: 1.2328\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 1.0859 - val_loss: 1.2564\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 1.0661 - val_loss: 1.2506\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Epoch 1/100\n",
      "491/491 - 2s - loss: 1.7370 - val_loss: 1.3211\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.2623 - val_loss: 1.2456\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 1.1969 - val_loss: 1.2252\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 1.1631 - val_loss: 1.2406\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 1.1389 - val_loss: 1.2340\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 1.1187 - val_loss: 1.2348\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 1.0987 - val_loss: 1.2347\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 1.0826 - val_loss: 1.2360\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Epoch 1/100\n",
      "491/491 - 2s - loss: 1.7445 - val_loss: 1.3465\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.2735 - val_loss: 1.2478\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 1.2058 - val_loss: 1.2277\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 1.1717 - val_loss: 1.2295\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 1.1441 - val_loss: 1.2208\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 1.1241 - val_loss: 1.2439\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 1.1037 - val_loss: 1.2177\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 1.0854 - val_loss: 1.2259\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 1.0717 - val_loss: 1.2359\n",
      "Epoch 10/100\n",
      "491/491 - 1s - loss: 1.0550 - val_loss: 1.2417\n",
      "Epoch 11/100\n",
      "491/491 - 1s - loss: 1.0379 - val_loss: 1.2401\n",
      "Epoch 12/100\n",
      "491/491 - 1s - loss: 1.0204 - val_loss: 1.2527\n",
      "Epoch 00012: early stopping\n",
      "3\n",
      "Epoch 1/100\n",
      "491/491 - 2s - loss: 1.7351 - val_loss: 1.3205\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.2512 - val_loss: 1.2469\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 1.1908 - val_loss: 1.2364\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 1.1639 - val_loss: 1.2292\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 1.1449 - val_loss: 1.2285\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 1.1271 - val_loss: 1.2295\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 1.1157 - val_loss: 1.2291\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 1.1006 - val_loss: 1.2365\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 1.0891 - val_loss: 1.2406\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Epoch 1/100\n",
      "491/491 - 1s - loss: 1.6478 - val_loss: 1.3100\n",
      "Epoch 2/100\n",
      "491/491 - 1s - loss: 1.2583 - val_loss: 1.2416\n",
      "Epoch 3/100\n",
      "491/491 - 1s - loss: 1.2044 - val_loss: 1.2329\n",
      "Epoch 4/100\n",
      "491/491 - 1s - loss: 1.1733 - val_loss: 1.2258\n",
      "Epoch 5/100\n",
      "491/491 - 1s - loss: 1.1478 - val_loss: 1.2292\n",
      "Epoch 6/100\n",
      "491/491 - 1s - loss: 1.1278 - val_loss: 1.2313\n",
      "Epoch 7/100\n",
      "491/491 - 1s - loss: 1.1038 - val_loss: 1.2339\n",
      "Epoch 8/100\n",
      "491/491 - 1s - loss: 1.0835 - val_loss: 1.2392\n",
      "Epoch 9/100\n",
      "491/491 - 1s - loss: 1.0626 - val_loss: 1.2590\n",
      "Epoch 00009: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "Final accuracy: 0.505062082139446\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y1, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Define ModelCheckpoint outside the loop\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights2.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "\n",
    "    # Build network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(y1.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n",
    "\n",
    "\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights(\"best_weights2.hdf5\",) # load weights from best model\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
