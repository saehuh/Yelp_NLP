{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from transformers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.data.processors.utils import InputExample\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm, tnrange \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_json('data/yelp_dataset/yelp_academic_dataset_review.json', lines=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(json_reader, nrows=10000, min_length=100, max_length = 128):\n",
    "    df = None\n",
    "    while True:\n",
    "        df_candidate = next(json_reader)\n",
    "        df_candidate = df_candidate.loc[(df_candidate['text'].str.len() > min_length) & (df_candidate['text'].str.len() <= max_length), ['text', 'stars']]\n",
    "        if df is None:\n",
    "            df = df_candidate\n",
    "        else:\n",
    "            df = df.append(df_candidate)\n",
    "        for rating in range(1, 6, 1):\n",
    "            df_rating = df[df['stars'] == rating]\n",
    "            if len(df_rating) > nrows//5:\n",
    "                df_rating = df_rating.iloc[:nrows//5, :]\n",
    "                df = df.loc[~(df['stars'] == rating), :]\n",
    "                df = df.append(df_rating)\n",
    "        if len(df) == nrows:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = generate_dataset(reader)\n",
    "test_df = generate_dataset(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2000\n",
       "4    2000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['stars'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2000\n",
       "4    2000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['stars'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = {'cumulative': True}\n",
    "plt.hist(train_df['text'].str.len().tolist() + test_df['text'].str.len().tolist(),cumulative=True, density=True, bins=40)\n",
    "plt.xlim(left=90, right=130) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10pm on a super bowl Sunday and they're alread...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>If you like the way cake mix from a box tastes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Not worth it. My friend and I both felt sick a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>No customer service as the \"help\" wander aroun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Worst place I've ever been , they don't care a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars\n",
       "16    10pm on a super bowl Sunday and they're alread...      1\n",
       "929   If you like the way cake mix from a box tastes...      1\n",
       "1181  Not worth it. My friend and I both felt sick a...      1\n",
       "1458  No customer service as the \"help\" wander aroun...      1\n",
       "1493  Worst place I've ever been , they don't care a...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c30a2b859948f29071ddce3a578ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8f293679d446dfb1be0754899e8b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30aabe56ad31437cbdc56326555cd65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model trainable parameters 108465077\n",
      "Total head trainable parameters 154805\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-33bd3d1a3ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total head trainable parameters {count_parameters(model)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=hidden_size)\n",
    "model.classifier.add_module('bert_activation', nn.Tanh())\n",
    "model.classifier.add_module('prediction', nn.Linear(hidden_size, 5))\n",
    "\n",
    "FINE_TUNE = True\n",
    "print(f'Total model trainable parameters {count_parameters(model)}')\n",
    "if FINE_TUNE:\n",
    "    for param in model.bert.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(f'Total head trainable parameters {count_parameters(model)}')\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(\n",
       "  in_features=768, out_features=200, bias=True\n",
       "  (bert_activation): Tanh()\n",
       "  (prediction): Linear(in_features=200, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'para', '##chu', '##ting', 'with', 'you']\n",
      "[146, 1821, 18311, 17143, 1916, 1114, 1128]\n",
      "[101, 146, 1821, 18311, 17143, 1916, 1114, 1128, 102]\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer.tokenize(' I am parachuting with you')\n",
    "print(tokenized)\n",
    "print(tokenizer.encode(tokenized, add_special_tokens=False))\n",
    "print(tokenizer.encode(tokenized, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/processors.html\n",
    "def get_features(df, text_col, label_col):\n",
    "    l = [InputExample(guid=idx, text_a=df.loc[idx, text_col], label=df.loc[idx, label_col]) for \n",
    "       idx, row in tqdm(df.iterrows(), total=df.shape[0])]\n",
    "    features = glue_convert_examples_to_features(examples=l, \n",
    "                                    tokenizer=tokenizer,\n",
    "                                    max_length=300,\n",
    "                                    label_list = df[label_col].values,\n",
    "                                    output_mode='regression')\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f.label-1 for f in features], dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db99cbd315ea45c89908bea0d131cb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saehuh/opt/anaconda3/lib/python3.7/site-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8b7b499d324cd0a7ed588704913005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_features(train_df, 'text', 'stars')\n",
    "test_dataset = get_features(test_df, 'text', 'stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx, train_idx = train_test_split(np.arange(len(train_dataset)), random_state=4, train_size=0.1)\n",
    "total_size = len(train_dataset)\n",
    "val_dataset = TensorDataset(*train_dataset[val_idx])\n",
    "train_dataset = TensorDataset(*train_dataset[train_idx])\n",
    "assert total_size == len(val_dataset) + len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1e706b9da5ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model(input_ids=train_dataset[:2][0].cuda(), \n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       labels=train_dataset[:2][2].cuda());\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# works\n",
    "model(input_ids=train_dataset[:2][0].cuda(), \n",
    "      attention_mask=train_dataset[:2][1].cuda(), \n",
    "      labels=train_dataset[:2][2].cuda());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "gradient_every = 32\n",
    "assert batch_size <= gradient_every and gradient_every % batch_size == 0\n",
    "\n",
    "accumulation_steps = gradient_every//batch_size\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size*2, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "lr = 0.002\n",
    "optimizer = AdamW(model.classifier.parameters(), lr=lr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_losses = []\n",
    "v_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016d6f38c2e14c9d9f134a490743abd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epoch', max=25.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d2d8b5aabd46878d7d2dc10128daa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='batch', max=563.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9017e438c598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         feed_dict = {'input_ids': input_ids.cuda(),\n\u001b[0m\u001b[1;32m      8\u001b[0m                      \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                      'labels': labels.cuda()}\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_data_loader)*epochs)\n",
    "for epoch in tnrange(epochs, desc='epoch'):\n",
    "    \"\"\" Training stage \"\"\"\n",
    "    epoch_tr_losses = []\n",
    "    print(f'epoch {epoch+1}')\n",
    "    for k, (input_ids, attention_mask, labels) in enumerate(tqdm(train_dataloader, total=len(train_dataloader), desc='batch')):\n",
    "        feed_dict = {'input_ids': input_ids.cuda(),\n",
    "                     'attention_mask': attention_mask.cuda(),\n",
    "                     'labels': labels.cuda()}\n",
    "        \n",
    "        loss, _ = model(**feed_dict)\n",
    "\n",
    "        # gradient accumulation\n",
    "        epoch_tr_losses.append(loss.item())\n",
    "        loss = loss/accumulation_steps\n",
    "        loss.backward()\n",
    "        if (k + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "    tr_losses.append(np.mean(epoch_tr_losses))\n",
    "    print(f'train NLL loss: {np.mean(epoch_tr_losses)}')\n",
    "  \n",
    "    \"\"\" Validation stage \"\"\"\n",
    "    epoch_v_losses = [] \n",
    "    with torch.no_grad():\n",
    "        for k, (input_ids, attention_mask, labels) in enumerate(tqdm(val_dataloader, total=len(val_dataloader), desc='val batch')):\n",
    "            feed_dict = {'input_ids': input_ids.cuda(),\n",
    "                         'attention_mask': attention_mask.cuda(),\n",
    "                         'labels': labels.cuda()} \n",
    "\n",
    "            loss, pred = model(**feed_dict)\n",
    "            epoch_v_losses.append(loss.item())\n",
    "        v_losses.append(np.mean(epoch_v_losses))\n",
    "    print(f'validation BCE loss: {np.mean(epoch_v_losses)}')\n",
    "    torch.save(model.classifier.state_dict(), f'/kaggle/working/yelp-head{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2530f0abe54e4555bc8a294192595d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='val batch', max=313.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7f3c60dddb6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         feed_dict = {'input_ids': input_ids.cuda(),\n\u001b[0m\u001b[1;32m      5\u001b[0m                      'attention_mask': attention_mask.cuda()} \n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "batch_predictions, batch_actual = [], []\n",
    "with torch.no_grad():\n",
    "    for k, (input_ids, attention_mask, labels) in enumerate(tqdm(test_dataloader, total=len(test_dataloader), desc='val batch')):\n",
    "        feed_dict = {'input_ids': input_ids.cuda(),\n",
    "                     'attention_mask': attention_mask.cuda()} \n",
    "        \n",
    "        pred = model(**feed_dict)[0].cpu()\n",
    "        batch_predictions.append(pred.numpy())\n",
    "        batch_actual.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6ad8700b46dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_predictions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_actual\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \"\"\"\n\u001b[0;32m-> 1186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "predictions = np.array([i for k in batch_predictions for i in k ])\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "actual = np.array([i for k in batch_actual for i in k ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2560040b9f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'actual' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(actual, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-754f0b4f9dc4>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-754f0b4f9dc4>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cmap=plt.cm.Blues):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7a5bc4c007d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconfusion_mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'actual' is not defined"
     ]
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "confusion_mtx = confusion_matrix(actual, predictions) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(1,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
